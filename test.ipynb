{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   parent_id         100 non-null    int64 \n",
      " 1   student_id        100 non-null    int64 \n",
      " 2   parent_name       100 non-null    object\n",
      " 3   relationship      100 non-null    object\n",
      " 4   income_level      100 non-null    object\n",
      " 5   income (monthly)  100 non-null    object\n",
      " 6   education_level   100 non-null    object\n",
      " 7   occupation        100 non-null    object\n",
      "dtypes: int64(2), object(6)\n",
      "memory usage: 6.4+ KB\n"
     ]
    }
   ],
   "source": [
    "parent_df = pd.read_csv('parents.csv')\n",
    "\n",
    "parent_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "parent_id           0\n",
       "student_id          0\n",
       "parent_name         0\n",
       "relationship        0\n",
       "income_level        0\n",
       "income (monthly)    0\n",
       "education_level     0\n",
       "occupation          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['parent_id', 'student_id', 'parent_name', 'relationship',\n",
       "       'income_level', 'income (monthly)', 'education_level', 'occupation'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['material_id', 'student_id', 'material_type', 'access_level',\n",
       "       'frequency_of_use'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "material_df = pd.read_csv(\"access_to_quality_material.csv\")\n",
    "\n",
    "material_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['activity_id', 'student_id', 'activity_name', 'participation_level',\n",
       "       'hours_per_week', 'Unnamed: 5'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activity_df = pd.read_csv(\"extra_curricullar.csv\")\n",
    "\n",
    "activity_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['resource_id', 'resource_type', 'allocation_hours', 'total_resources',\n",
       "       'usage_frequency'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resource_df = pd.read_csv(\"resource.csv\")\n",
    "\n",
    "resource_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['student_id', 'first_name', 'last_name', 'gender', 'date_of_birth',\n",
       "       'class', 'admission_date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_df = pd.read_csv(\"student_bio_data.csv\")\n",
    "\n",
    "student_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['teacher_id', 'subject', 'teaching_method', 'student_feedback_rating',\n",
       "       'hours_per_week'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_df = pd.read_csv(\"teaching_quality.csv\")\n",
    "\n",
    "teacher_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in the merged dataset:\n",
      "parent_id            0\n",
      "student_id           0\n",
      "parent_name          0\n",
      "relationship         0\n",
      "income_level         0\n",
      "income (monthly)     0\n",
      "education_level      0\n",
      "occupation           0\n",
      "material_id         51\n",
      "material_type       51\n",
      "access_level        51\n",
      "frequency_of_use    51\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_id</th>\n",
       "      <th>student_id</th>\n",
       "      <th>parent_name</th>\n",
       "      <th>relationship</th>\n",
       "      <th>income_level</th>\n",
       "      <th>income (monthly)</th>\n",
       "      <th>education_level</th>\n",
       "      <th>occupation</th>\n",
       "      <th>material_id</th>\n",
       "      <th>material_type</th>\n",
       "      <th>access_level</th>\n",
       "      <th>frequency_of_use</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2021001</td>\n",
       "      <td>Emeka Okafor</td>\n",
       "      <td>Father</td>\n",
       "      <td>Upper Class</td>\n",
       "      <td>?5,000,000</td>\n",
       "      <td>University</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Textbook</td>\n",
       "      <td>High</td>\n",
       "      <td>Daily</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2021002</td>\n",
       "      <td>Amina Bello</td>\n",
       "      <td>Mother</td>\n",
       "      <td>Lower Upper Class</td>\n",
       "      <td>?2,500,000</td>\n",
       "      <td>Secondary</td>\n",
       "      <td>Trader</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Online Resource</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Weekly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2021003</td>\n",
       "      <td>Thandi Molefe</td>\n",
       "      <td>Mother</td>\n",
       "      <td>Middle Class</td>\n",
       "      <td>?800,000</td>\n",
       "      <td>University</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Library Access</td>\n",
       "      <td>Low</td>\n",
       "      <td>Monthly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2021004</td>\n",
       "      <td>Ibrahim Abubakar</td>\n",
       "      <td>Father</td>\n",
       "      <td>Lower Class</td>\n",
       "      <td>?100,000</td>\n",
       "      <td>Primary</td>\n",
       "      <td>Farmer</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Textbook</td>\n",
       "      <td>High</td>\n",
       "      <td>Daily</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2021005</td>\n",
       "      <td>Akosua Mensah</td>\n",
       "      <td>Mother</td>\n",
       "      <td>Upper Class</td>\n",
       "      <td>?6,000,000</td>\n",
       "      <td>University</td>\n",
       "      <td>Doctor</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Online Resource</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Weekly</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   parent_id  student_id       parent_name relationship       income_level  \\\n",
       "0          1     2021001      Emeka Okafor       Father        Upper Class   \n",
       "1          2     2021002       Amina Bello       Mother  Lower Upper Class   \n",
       "2          3     2021003     Thandi Molefe       Mother       Middle Class   \n",
       "3          4     2021004  Ibrahim Abubakar       Father        Lower Class   \n",
       "4          5     2021005     Akosua Mensah       Mother        Upper Class   \n",
       "\n",
       "  income (monthly) education_level occupation  material_id    material_type  \\\n",
       "0       ?5,000,000      University   Engineer          1.0         Textbook   \n",
       "1       ?2,500,000       Secondary     Trader          2.0  Online Resource   \n",
       "2         ?800,000      University    Teacher          3.0   Library Access   \n",
       "3         ?100,000         Primary     Farmer          4.0         Textbook   \n",
       "4       ?6,000,000      University     Doctor          5.0  Online Resource   \n",
       "\n",
       "  access_level frequency_of_use  \n",
       "0         High            Daily  \n",
       "1       Medium           Weekly  \n",
       "2          Low          Monthly  \n",
       "3         High            Daily  \n",
       "4       Medium           Weekly  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform the merge\n",
    "merged_df = pd.merge(\n",
    "    df,\n",
    "    dff,\n",
    "    on='student_id',\n",
    "    how='outer'  # Use outer join to keep all records from both datasets\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# 2. Sort the dataset by student_id\n",
    "merged_df = merged_df.sort_values('student_id')\n",
    "\n",
    "# 3. Reset the index\n",
    "merged_df = merged_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Merge datasets with student_id\n",
    "def merge_student_datasets():\n",
    "    # First merge parent and material data\n",
    "    merged_df = pd.merge(\n",
    "        df,\n",
    "        dff,\n",
    "        on='student_id',\n",
    "        how='outer',\n",
    "        suffixes=('_parent', '_material')\n",
    "    )\n",
    "    \n",
    "    # Then merge with activity data\n",
    "    merged_df = pd.merge(\n",
    "        merged_df,\n",
    "        dfff,\n",
    "        on='student_id',\n",
    "        how='outer',\n",
    "        suffixes=('', '_activity')\n",
    "    )\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "# Step 2: Create a cross join with resources (as it doesn't have student_id)\n",
    "def add_resources(merged_df):\n",
    "    # Create a cross join by using merge with dummy key\n",
    "    merged_df['dummy_key'] = 1\n",
    "    dffff['dummy_key'] = 1\n",
    "    \n",
    "    final_df = pd.merge(\n",
    "        merged_df,\n",
    "        dffff,\n",
    "        on='dummy_key',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Remove the dummy key\n",
    "    final_df = final_df.drop('dummy_key', axis=1)\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "# Step 3: Clean and prepare the final dataset\n",
    "def clean_dataset(df):\n",
    "    # Remove any duplicate columns\n",
    "    df = df.loc[:,~df.columns.duplicated()]\n",
    "    \n",
    "    # Sort by student_id\n",
    "    df = df.sort_values('student_id')\n",
    "    \n",
    "    # Reset index\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    # Clean column names\n",
    "    df.columns = [col.strip() for col in df.columns]\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Execute the merging process\n",
    "merged_df = merge_student_datasets()\n",
    "final_df = add_resources(merged_df)\n",
    "final_df = clean_dataset(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_id</th>\n",
       "      <th>student_id</th>\n",
       "      <th>parent_name</th>\n",
       "      <th>relationship</th>\n",
       "      <th>income_level</th>\n",
       "      <th>income (monthly)</th>\n",
       "      <th>education_level</th>\n",
       "      <th>occupation</th>\n",
       "      <th>material_id</th>\n",
       "      <th>material_type</th>\n",
       "      <th>...</th>\n",
       "      <th>activity_id</th>\n",
       "      <th>activity_name</th>\n",
       "      <th>participation_level</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>resource_id</th>\n",
       "      <th>resource_type</th>\n",
       "      <th>allocation_hours</th>\n",
       "      <th>total_resources</th>\n",
       "      <th>usage_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2021001</td>\n",
       "      <td>Emeka Okafor</td>\n",
       "      <td>Father</td>\n",
       "      <td>Upper Class</td>\n",
       "      <td>?5,000,000</td>\n",
       "      <td>University</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Textbook</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Football</td>\n",
       "      <td>High</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Library</td>\n",
       "      <td>20</td>\n",
       "      <td>200</td>\n",
       "      <td>Daily</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2021001</td>\n",
       "      <td>Emeka Okafor</td>\n",
       "      <td>Father</td>\n",
       "      <td>Upper Class</td>\n",
       "      <td>?5,000,000</td>\n",
       "      <td>University</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Textbook</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Football</td>\n",
       "      <td>High</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "      <td>Media Room</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Monthly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2021001</td>\n",
       "      <td>Emeka Okafor</td>\n",
       "      <td>Father</td>\n",
       "      <td>Upper Class</td>\n",
       "      <td>?5,000,000</td>\n",
       "      <td>University</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Textbook</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Football</td>\n",
       "      <td>High</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>Language Lab</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>Weekly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2021001</td>\n",
       "      <td>Emeka Okafor</td>\n",
       "      <td>Father</td>\n",
       "      <td>Upper Class</td>\n",
       "      <td>?5,000,000</td>\n",
       "      <td>University</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Textbook</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Football</td>\n",
       "      <td>High</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>Robotics Lab</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>Bi-weekly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2021001</td>\n",
       "      <td>Emeka Okafor</td>\n",
       "      <td>Father</td>\n",
       "      <td>Upper Class</td>\n",
       "      <td>?5,000,000</td>\n",
       "      <td>University</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Textbook</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Football</td>\n",
       "      <td>High</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31</td>\n",
       "      <td>Debate Room</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>Monthly</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   parent_id  student_id   parent_name relationship income_level  \\\n",
       "0          1     2021001  Emeka Okafor       Father  Upper Class   \n",
       "1          1     2021001  Emeka Okafor       Father  Upper Class   \n",
       "2          1     2021001  Emeka Okafor       Father  Upper Class   \n",
       "3          1     2021001  Emeka Okafor       Father  Upper Class   \n",
       "4          1     2021001  Emeka Okafor       Father  Upper Class   \n",
       "\n",
       "  income (monthly) education_level occupation  material_id material_type  ...  \\\n",
       "0       ?5,000,000      University   Engineer          1.0      Textbook  ...   \n",
       "1       ?5,000,000      University   Engineer          1.0      Textbook  ...   \n",
       "2       ?5,000,000      University   Engineer          1.0      Textbook  ...   \n",
       "3       ?5,000,000      University   Engineer          1.0      Textbook  ...   \n",
       "4       ?5,000,000      University   Engineer          1.0      Textbook  ...   \n",
       "\n",
       "  activity_id activity_name  participation_level hours_per_week Unnamed: 5  \\\n",
       "0           1      Football                 High              5        NaN   \n",
       "1           1      Football                 High              5        NaN   \n",
       "2           1      Football                 High              5        NaN   \n",
       "3           1      Football                 High              5        NaN   \n",
       "4           1      Football                 High              5        NaN   \n",
       "\n",
       "  resource_id resource_type  allocation_hours total_resources  usage_frequency  \n",
       "0           1       Library                20             200            Daily  \n",
       "1          28    Media Room                10               1          Monthly  \n",
       "2          29  Language Lab                20               4           Weekly  \n",
       "3          30  Robotics Lab                15               3        Bi-weekly  \n",
       "4          31   Debate Room                10               2          Monthly  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_37766/3439259647.py:7: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  student_df['date_of_birth'] = pd.to_datetime(student_df['date_of_birth'])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot convert from timedelta64[ns] to timedelta64[Y]. Supported resolutions are 's', 'ms', 'us', 'ns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 120\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m final_df, summary_stats\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# Run the main function\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m final_df, summary_stats \u001b[38;5;241m=\u001b[39m main()\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# Display sample of the final dataset\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== Sample of Final Dataset ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[27], line 106\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;66;03m# Preprocess the datasets\u001b[39;00m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mglobal\u001b[39;00m student_df\n\u001b[0;32m--> 106\u001b[0m     student_df \u001b[38;5;241m=\u001b[39m preprocess_datasets()\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;66;03m# Merge all datasets\u001b[39;00m\n\u001b[1;32m    109\u001b[0m     final_df \u001b[38;5;241m=\u001b[39m merge_datasets()\n",
      "Cell \u001b[0;32mIn[27], line 11\u001b[0m, in \u001b[0;36mpreprocess_datasets\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m student_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madmission_date\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(student_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madmission_date\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Calculate age\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m student_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (datetime\u001b[38;5;241m.\u001b[39mnow() \u001b[38;5;241m-\u001b[39m student_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate_of_birth\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<m8[Y]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m student_df\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:6534\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6530\u001b[0m     results \u001b[38;5;241m=\u001b[39m [ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()]\n\u001b[1;32m   6532\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6533\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6534\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mastype(dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   6535\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m   6536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/managers.py:414\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    412\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 414\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    416\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    417\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m    418\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    419\u001b[0m     using_cow\u001b[38;5;241m=\u001b[39musing_copy_on_write(),\n\u001b[1;32m    420\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/managers.py:354\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 354\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    355\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    357\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/blocks.py:616\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors, using_cow)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;124;03mCoerce to the new dtype.\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;124;03mBlock\u001b[39;00m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    614\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m--> 616\u001b[0m new_values \u001b[38;5;241m=\u001b[39m astype_array_safe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m    618\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    620\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:238\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    235\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 238\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m astype_array(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:180\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m values\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;66;03m# i.e. ExtensionArray\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    183\u001b[0m     values \u001b[38;5;241m=\u001b[39m _astype_nansafe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/timedeltas.py:380\u001b[0m, in \u001b[0;36mTimedeltaArray.astype\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_simple_new(\n\u001b[1;32m    377\u001b[0m             res_values, dtype\u001b[38;5;241m=\u001b[39mres_values\u001b[38;5;241m.\u001b[39mdtype, freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfreq\n\u001b[1;32m    378\u001b[0m         )\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 380\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    381\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot convert from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    382\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSupported resolutions are \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mms\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mus\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mns\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    383\u001b[0m         )\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dtl\u001b[38;5;241m.\u001b[39mDatetimeLikeArrayMixin\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mself\u001b[39m, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot convert from timedelta64[ns] to timedelta64[Y]. Supported resolutions are 's', 'ms', 'us', 'ns'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_datasets():\n",
    "    \"\"\"Preprocess the datasets by converting dates and calculating age\"\"\"\n",
    "    # Convert date columns to datetime\n",
    "    student_df['date_of_birth'] = pd.to_datetime(student_df['date_of_birth'])\n",
    "    student_df['admission_date'] = pd.to_datetime(student_df['admission_date'])\n",
    "    \n",
    "    # Calculate age\n",
    "    today = pd.Timestamp.today()\n",
    "    student_df['age'] = (today - student_df['date_of_birth']).dt.days / 365.25\n",
    "    student_df['age'] = student_df['age'].astype(int)\n",
    "\n",
    "\n",
    "    return student_df\n",
    "\n",
    "def merge_datasets():\n",
    "    \"\"\"Merge all datasets together\"\"\"\n",
    "    # Start with student personal information as the base\n",
    "    merged_df = student_df.copy()\n",
    "    \n",
    "    # Merge with parent information\n",
    "    merged_df = pd.merge(\n",
    "        merged_df,\n",
    "        parent_df,\n",
    "        on='student_id',\n",
    "        how='left',\n",
    "        suffixes=('', '_parent')\n",
    "    )\n",
    "    \n",
    "    # Merge with materials\n",
    "    merged_df = pd.merge(\n",
    "        merged_df,\n",
    "        material_df,\n",
    "        on='student_id',\n",
    "        how='left',\n",
    "        suffixes=('', '_material')\n",
    "    )\n",
    "    \n",
    "    # Merge with activities\n",
    "    merged_df = pd.merge(\n",
    "        merged_df,\n",
    "        activity_df,\n",
    "        on='student_id',\n",
    "        how='left',\n",
    "        suffixes=('', '_activity')\n",
    "    )\n",
    "    \n",
    "    # Add resource information (as a cross join since no direct relationship)\n",
    "    merged_df['dummy_key'] = 1\n",
    "    resource_df['dummy_key'] = 1\n",
    "    merged_df = pd.merge(\n",
    "        merged_df,\n",
    "        resource_df,\n",
    "        on='dummy_key',\n",
    "        how='left'\n",
    "    ).drop('dummy_key', axis=1)\n",
    "    \n",
    "    # Add teacher information (as a cross join to show all possible teachers for each student)\n",
    "    merged_df['dummy_key'] = 1\n",
    "    teacher_df['dummy_key'] = 1\n",
    "    merged_df = pd.merge(\n",
    "        merged_df,\n",
    "        teacher_df,\n",
    "        on='dummy_key',\n",
    "        how='left'\n",
    "    ).drop('dummy_key', axis=1)\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "def clean_and_validate_data(df):\n",
    "    \"\"\"Clean and validate the final dataset\"\"\"\n",
    "    # Remove any duplicate columns\n",
    "    df = df.loc[:,~df.columns.duplicated()]\n",
    "    \n",
    "    # Sort by student_id\n",
    "    df = df.sort_values('student_id')\n",
    "    \n",
    "    # Reset index\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    # Clean column names\n",
    "    df.columns = [col.strip() for col in df.columns]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def generate_summary_statistics(df):\n",
    "    \"\"\"Generate summary statistics for the dataset\"\"\"\n",
    "    print(\"\\n=== Dataset Summary ===\")\n",
    "    print(f\"Total number of records: {len(df)}\")\n",
    "    print(f\"Number of unique students: {df['student_id'].nunique()}\")\n",
    "    print(f\"Number of unique teachers: {df['teacher_id'].nunique()}\")\n",
    "    print(f\"Number of classes: {df['class'].nunique()}\")\n",
    "    \n",
    "    print(\"\\n=== Missing Data Analysis ===\")\n",
    "    missing_data = (df.isnull().sum() / len(df) * 100).round(2)\n",
    "    print(missing_data[missing_data > 0])\n",
    "    \n",
    "    print(\"\\n=== Key Metrics ===\")\n",
    "    print(f\"Average student age: {df['age'].mean():.2f} years\")\n",
    "    print(f\"Average teacher rating: {df['student_feedback_rating'].mean():.2f}\")\n",
    "    \n",
    "    return df.describe()\n",
    "\n",
    "def main():\n",
    "    # Preprocess the datasets\n",
    "    global student_df\n",
    "    student_df = preprocess_datasets()\n",
    "    \n",
    "    # Merge all datasets\n",
    "    final_df = merge_datasets()\n",
    "    \n",
    "    # Clean and validate\n",
    "    final_df = clean_and_validate_data(final_df)\n",
    "    \n",
    "    # Generate summary statistics\n",
    "    summary_stats = generate_summary_statistics(final_df)\n",
    "    \n",
    "    return final_df, summary_stats\n",
    "\n",
    "# Run the main function\n",
    "final_df, summary_stats = main()\n",
    "\n",
    "# Display sample of the final dataset\n",
    "print(\"\\n=== Sample of Final Dataset ===\")\n",
    "print(final_df[['student_id', 'first_name', 'class', 'teacher_id', 'subject', 'activity_name', 'material_type']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'date_of_birth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'date_of_birth'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 101\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m final_df, \n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# Run the main function\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m final_df \u001b[38;5;241m=\u001b[39m main()\n",
      "Cell \u001b[0;32mIn[18], line 88\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;66;03m# Preprocess the datasets\u001b[39;00m\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mglobal\u001b[39;00m student_df\n\u001b[0;32m---> 88\u001b[0m     student_df \u001b[38;5;241m=\u001b[39m preprocess_datasets()\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;66;03m# Merge all datasets\u001b[39;00m\n\u001b[1;32m     91\u001b[0m     final_df \u001b[38;5;241m=\u001b[39m merge_datasets()\n",
      "Cell \u001b[0;32mIn[18], line 7\u001b[0m, in \u001b[0;36mpreprocess_datasets\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_datasets\u001b[39m():\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Convert date columns to datetime\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     dfffff[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate_of_birth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(dffff[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate_of_birth\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      8\u001b[0m     dfffff[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madmission_date\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(dfffff[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madmission_date\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# Calculate age (this will help in analysis)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3794\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3795\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3796\u001b[0m     ):\n\u001b[1;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'date_of_birth'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def preprocess_datasets():\n",
    "    # Convert date columns to datetime\n",
    "    dfffff['date_of_birth'] = pd.to_datetime(dffff['date_of_birth'])\n",
    "    dfffff['admission_date'] = pd.to_datetime(dfffff['admission_date'])\n",
    "    \n",
    "    # Calculate age (this will help in analysis)\n",
    "    dfffff['age'] = (datetime.now() - dfffff['date_of_birth']).astype('<m8[Y]')\n",
    "    \n",
    "    return dfffff\n",
    "\n",
    "def merge_datasets():\n",
    "    \"\"\"Merge all datasets that have student_id as key\"\"\"\n",
    "    # Start with student personal information\n",
    "    merged_df = dfffff.copy()\n",
    "    \n",
    "    # Merge with parent information\n",
    "    merged_df = pd.merge(\n",
    "        merged_df,\n",
    "        df,\n",
    "        on='student_id',\n",
    "        how='left',\n",
    "        suffixes=('', '_parent')\n",
    "    )\n",
    "    \n",
    "    # Merge with materials\n",
    "    merged_df = pd.merge(\n",
    "        merged_df,\n",
    "        dff,\n",
    "        on='student_id',\n",
    "        how='left',\n",
    "        suffixes=('', '_material')\n",
    "    )\n",
    "    \n",
    "    # Merge with activities\n",
    "    merged_df = pd.merge(\n",
    "        merged_df,\n",
    "        dfff,\n",
    "        on='student_id',\n",
    "        how='left',\n",
    "        suffixes=('', '_activity')\n",
    "    )\n",
    "    \n",
    "     # Add resource information (as a cross join since no direct relationship)\n",
    "    merged_df['dummy_key'] = 1\n",
    "    dffff['dummy_key'] = 1\n",
    "    merged_df = pd.merge(\n",
    "        merged_df,\n",
    "        dffff,\n",
    "        on='dummy_key',\n",
    "        how='left'\n",
    "    ).drop('dummy_key', axis=1)\n",
    "    \n",
    "    # Add teacher information (as a cross join to show all possible teachers for each student)\n",
    "    merged_df['dummy_key'] = 1\n",
    "    dffffff['dummy_key'] = 1\n",
    "    merged_df = pd.merge(\n",
    "        merged_df,\n",
    "        dffffff,\n",
    "        on='dummy_key',\n",
    "        how='left'\n",
    "    ).drop('dummy_key', axis=1)\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "def clean_and_validate_data(df):\n",
    "    \"\"\"Clean and validate the final dataset\"\"\"\n",
    "    # Remove any duplicate columns\n",
    "    df = df.loc[:,~df.columns.duplicated()]\n",
    "    \n",
    "    # Sort by student_id\n",
    "    df = df.sort_values('student_id')\n",
    "    \n",
    "    # Reset index\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    # Clean column names\n",
    "    df.columns = [col.strip() for col in df.columns]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    # Preprocess the datasets\n",
    "    global student_df\n",
    "    student_df = preprocess_datasets()\n",
    "    \n",
    "    # Merge all datasets\n",
    "    final_df = merge_datasets()\n",
    "    \n",
    "    # Clean and validate\n",
    "    final_df = clean_and_validate_data(final_df)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return final_df, \n",
    "\n",
    "# Run the main function\n",
    "final_df = main()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
